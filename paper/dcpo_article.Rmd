---
output: 
  pdf_document:
    citation_package: natbib
    keep_tex: false
    fig_caption: true
    latex_engine: pdflatex
    template: svm-latex-ms2.tex
title: "Dynamic Comparative Public Opinion"
thanks: "The paper's revision history and the materials needed to reproduce its analyses can be found [on Github here](http://github.com/fsolt/dcpo_article).  I am grateful for comments received at the 2014 meetings of the European Political Science Association and American Political Science Association, the 2016 meeting of the Midwest Political Science Association, and at Princeton University, Oxford University, the University of Tennessee, the University of Iowa, Central European University, and the Polish Academy of Sciences.  Corresponding author: [frederick-solt@uiowa.edu](mailto:frederick-solt@uiowa.edu). Current version: `r format(Sys.time(), '%B %d, %Y')`."
author:
- name: Frederick Solt
  affiliation: University of Iowa
abstract: "The study of public opinion in comparative context has been hampered by data that is sparse, that is, unavailable for many countries and years; incomparable, i.e., ostensibly addressing the same issue but generated by different survey items; or, most often, both.  Questions of representation and of policy feedback on public opinion, for example, cannot be explored fully from a cross-national perspective without comparable time-series data for many countries that span their respective times of policy adoption.  This paper proposes a latent variable approach to the study of comparative public opinion that maximizes the information gleaned from available surveys to overcome issues of missing and incomparable data and allow comparativists to examine the dynamics of public opinion.  It then presents Bayesian techniques for estimating latent variables from cross-national survey data."
keywords: "public opinion, item response theory, measurement"
date: "`r format(Sys.time(), '%B %d, %Y')`"
fontsize: 11pt
spacing: single
bibliography: \dummy{`r file.path(getwd(), list.files(getwd(), ".bib$"))`}
biblio-style: apsr
citecolor: black
linkcolor: black
endnote: no
header-includes:
      - \usepackage{array}
      - \usepackage{caption}
      - \usepackage{graphicx}
      - \usepackage{siunitx}
      - \usepackage{colortbl}
      - \usepackage{multirow}
      - \usepackage{hhline}
      - \usepackage{calc}
      - \usepackage{tabularx}
      - \usepackage{threeparttable}
      - \usepackage{wrapfig}
---

```{r, include=FALSE}
options(tinytex.verbose = TRUE)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
# load all the packages you will use below 
library(huxtable)
library(kableExtra)
library(DCPOtools)
library(tidyverse)

```

A wealth of surveys provide information on the state of public opinion on various issues in different countries over the years, but scholars have faced significant hurdles to putting all of this information to use in any comparative study.  The most challenging of these obstacles is that, across countries and over time, the questions asked regarding any given issue are rarely the same, making responses to these questions incomparable.

As a result, the most common approach to the study of comparative public opinion is to use a single cross-section, typically provided by a single cross-national survey [see, e.g., @Dalton2011, @Ansell2014].
    Some works have captured some element of change over time by taking advantage of multiple waves of an ongoing cross-national survey [see, e.g., @Inglehart1997, @Inglehart2005] or, more rarely, drawing on multiple surveys that employed the same item [see, e.g., @Solt2011, @Ezrow2014].

A growing body of work is taking a different tack, examining the dynamics of public opinion in single countries over time.  These studies draw on

(Not using stimson: Hobolt2008, McGann2014, Stubager2015)

dynamic comparative: Hagemann2016

field of comparative public opinion
lack of dynamics (in contrast to public opinion work in U.S.)
Check out
	Thomassen2011
	Russell Dalton's work
	Norris on trust (2011, 63-77)


problem: 	scarce data
		perennial problem of public opinion research: exact question wanted is rarely asked
		no (good) way to (fully) integrate what does exist

question of feedback: positive or negative? ("policies create constituencies" vs. thermostatic) under what conditions?





## A Method for Estimating Dynamic Comparative Public Opinion

solution:
    informed by recent efforts to improve data quality of cross-national time-series data on other latent concepts, such as democracy (Treier and Jackman 2008; Pemstein, Meserve, and Melton 2010, [Arel-Bundock and Mebane 2011]) and judicial independence (Linzer and Staton [2013]), I offer a Bayesian measurement model for comparative public opinion

priors for scarce data: Bailey (2001)
Bayesian for missing data: Jackman (2000)
random walk for flexibility: Linzer and Staton [2013]
heteroskedastic ideal points: Lauderdale (2010) -- actually not heteroskedastic (no gammas)
    no risk of outside raters doing a worse job with some countries because no outsiders: public opinion is what it is

```{r comparison_table}
comparison_data <- tibble::tribble(
    ~` `, ~`McGann (2014)`, ~`Claassen (2019)`, ~`\\vtop{\\hbox{\\strut Caughley, O'Grady,}\\hbox{\\strut and Warshaw (2019)}}`, ~DCPO,
    "\\vtop{\\hbox{\\strut Cross-National}\\hbox{\\strut }}", "No", "Yes", "Yes", "Yes",
    "\\vtop{\\hbox{\\strut Ordinal}\\hbox{\\strut }}", "No", "No", "Yes", "Yes",
    "\\vtop{\\hbox{\\strut Country-Varying}\\hbox{\\strut Question Difficulty}}", "No", "Yes", "No", "Yes",
    "\\vtop{\\hbox{\\strut Bounded}\\hbox{\\strut }}", "Yes", "No", "No", "Yes",
    "\\vtop{\\hbox{\\strut Country-Year}\\hbox{\\strut Population Variance}}", "Yes", "No", "No", "Yes"
)

comparison_ht <- comparison_data %>%
    as_hux() %>% 
    add_colnames() %>% 
    set_bold(1, 1:5, TRUE) %>% 
    set_bottom_border(1, 1:5, 1) %>%
    set_caption('Comparing IRT Models of Aggregate Public Opinion') %>% 
    set_position("left") %>% 
    set_escape_contents(everywhere, everywhere, FALSE) %>% 
    set_background_color(evens, everywhere, "grey95") %>% 
    set_align(-1, -1, "center")

comparison_ht

```

## Modeling Dynamic Comparative Public Opinion

### Group IRT

The two-parameter logistic IRT model 


@Mislevy1983

### Ordinal

Cumulative logit 

### Country-Varying Question Difficulty

Responses to survey questions may vary across different countries not only as a result of differences in attitudes and preferences but also due to translation issues [see, e.g., @Davidov2010], cultural differences in response styles [see, e.g., @VanHerk2004], or other idiosyncrasies---recall Tarrow's [-@Tarrow1971, 344] famous observation that the French understood survey questions regarding their "interest in politics" as inquiring about the strength of their partisan affiliations.
Rather than simply allowing such problems of equivalence to contribute to the error of the model, they can be addressed explicitly by modeling the country-specific item bias  [@Stegmueller2011], $\delta_{kq}$.
Claassen's [-@Claassen2019, 5-6] work employs this technique, and because estimating $\delta_{kq}$ requires data from repeated administrations of question $q$ in country $k$, it discards survey data that does not meet this requirement.
DCPO also incorporates $\delta_{kq}$ to capture country-specific item bias, but it takes a slightly different approach that aims to maximize the incorporation of available survey data: when responses to question $q$ are observed in country $k$ in only a single year, $\delta_{kq}$ is set to zero by assumption.
This means that incorporating these 'one-shot' surveys will come at the cost of increasing the error of the model by any country-item bias that is present.

### Bounded

Previous efforts to measure cross-national aggregate public opinion as a latent variable have generated estimates on an unbounded scale with mean zero and unit variance [see @Claassen2019, 14; @Caughey2019, 8].
However, like many other concepts in political science [see @Linzer2015, 229], many aspects of public opinion are conceptually bounded, that is, it make sense to think of them as lying along a scale from fully absent to fully present in the relevant public.
Take attitudes toward immigration as an example.
One hypothetical country's citizens are absolutely opposed to any immigration, while another's are completely welcoming to migrants.
Actual countries' levels of public opinion toward immigration are better understood not as unbounded but as falling somewhere between the bounds described by these two hypothetical countries.
It is not surprising, then, that earlier works aggregating public opinion within a single country presented results on bounded scales [see @Stimson1991; @McGann2014].
Even if the issue in question is less easily viewed as bounded, bounding is still a good idea because it reduces the uncertainty for the estimates for countries at the extremes, that is, those countries that should in fact be easier to estimate.
As Linzer and Staton [-@Linzer2015, 229] write, "bounding the latent variable may do little harm to the scale and produce more sensible estimates of uncertainty."
DCPO therefore bounds estimates of aggregate public opinion to range between zero and one.

### Country-Year Population Variance

The probability of an individual $i$ in country $k$ at time $t$ giving a response at least as positive as response $r$ to question $q$ is:

\begin{equation}
Pr(Y \geq r) = logit^{-1}(\frac{\bar{\theta}_{kt}' - (\beta_{qr} + \delta_{kq})}{\sqrt{\alpha_{q}^2 + \sigma_{kt}^2}})
\end{equation}

%McGann2014, 125: ``the IRT model has the added advantages of being better justified in terms of individual-level behavior and the additional parameters (the polarization of the population in terms of policy mood) are substantively interesting.''



### Adding Dynamics

Random walk priors for $\bar{\theta}_{kt}$ and $\sigma_{kt}^2$


### Identification, Priors, and Estimation

For each question $q$, $\delta_{kq}$ are constrained to have mean equal to zero.



## Conclusions
strengths:
    makes maximum use of available data
	permits testing hypotheses regarding change over time
	incorporates uncertainty

weaknesses:
	data collection demands
	challenges at individual level (but subsets)



Single-country studies of public opinion have flourished since the release of Stimson's [-@Stimson1991] algorithm for identifying the common trends in any collection of survey questions that have been repeatedly asked over many years.  By extending this work to allow the creation of cross-national pooled time series that identify how public opinion varies both across countries and over time, DCPO has the potential to trigger a new wave of research on the causes and consequences of public opinion that will take into account the experiences of many countries.

Further, this allows a broadly comparative approach that is new to work on the relationship between opinion and policy.  Existing studies on that examine this topic over time investigate only a single country or, much more rarely, a handful of countries.  By examining a broad sample of democracies, DCPO helps researchers avoid conclusions based on the idiosyncrasies of any given political setting and provide a firmer grounding for our understanding of how democracies work and the threats to representation that they face.


```{r validation}
load("~/Documents/Projects/dcpo_article/data/church_21_1k_09-07-22-50.rda")
ivt_dcpo <- DCPOtools::internal_validation_tests(demsup_data, out1)

load("~/Documents/Projects/dcpo_article/data/claassen_m5_1k_07-15-10-25.rda")
ivt_claassen <- DCPOtools::internal_validation_tests(demsup_claassen, claassen_m5, "claassen")

load("~/Documents/Projects/dcpo_article/data/dgirt/demsup_dgirt_50_08-13-01-55.rda")
ivt_dgirt <- DCPOtools::internal_validation_tests(demsup_data_dgirt, out1, "dgirt")

bind_rows(ivt_claassen, ivt_dgirt, ivt_dcpo) %>% 
    select(-loo_ic)
```

